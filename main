import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "2"

import numpy as np
import pandas as pd
import re
import sys
import random
from collections import Counter
from Bio import SeqIO
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import (confusion_matrix, matthews_corrcoef, accuracy_score, precision_score, recall_score,
                             f1_score, precision_recall_curve, auc)
from sklearn.preprocessing import StandardScaler

# Load DNA sequences
def read_nucleotide_sequences(file):
    if not os.path.exists(file):
        print(f'Error: file {file} does not exist.')
        sys.exit(1)

    with open(file) as f:
        records = f.read()
    if '>' not in records:
        print(f'Error: the input file {file} seems not in FASTA format!')
        sys.exit(1)

    fasta_sequences = []
    records = records.split('>')[1:]
    for fasta in records:
        array = fasta.split('\n')
        header, sequence = array[0].split()[0], re.sub('[^ACGTU-]', '-', ''.join(array[1:]).upper())
        header_array = header.split('|')
        name = header_array[0]
        label = header_array[1] if len(header_array) >= 2 else '0'
        sequence = re.sub('U', 'T', sequence)
        fasta_sequences.append([name, sequence, label])
    return fasta_sequences

# --- Encoding Functions ---
def CKSNAP(fastas, gap):
    AA = 'ACGT'
    aaPairs = [a1 + a2 for a1 in AA for a2 in AA]
    encodings = []
    for i in fastas:
        sequence = i[1]
        code = []
        for g in range(gap + 1):
            myDict = dict.fromkeys(aaPairs, 0)
            total = 0
            for j in range(len(sequence) - g - 1):
                pair = sequence[j] + sequence[j + g + 1]
                if pair in myDict:
                    myDict[pair] += 1
                    total += 1
            for pair in aaPairs:
                code.append(myDict[pair] / total if total > 0 else 0)
        encodings.append(code)
    return np.array(encodings)

chemical_property = {'A': [1, 1, 1], 'C': [0, 1, 0], 'G': [1, 0, 0], 'T': [0, 0, 1], '-': [0, 0, 0]}
def NCP(fastas):
    encodings = []
    for i in fastas:
        seq = i[1]
        code = []
        for s in seq:
            code.extend(chemical_property.get(s, [0, 0, 0]))
        encodings.append(code)
    return np.array(encodings)

def dataProcessing(path, fileformat):
    all_seq_data = []
    for record in SeqIO.parse(path, fileformat):
        seq_data = []
        for s in record.seq:
            if s == 'A': seq_data.append([1, 0, 0, 0])
            elif s == 'T' or s == 'U': seq_data.append([0, 1, 0, 0])
            elif s == 'C': seq_data.append([0, 0, 1, 0])
            elif s == 'G': seq_data.append([0, 0, 0, 1])
            else: seq_data.append([0, 0, 0, 0])
        all_seq_data.append(seq_data)
    return np.array(all_seq_data).reshape(len(all_seq_data), -1)

def TNC(fastas):
    AA = 'ACGT'
    AADict = {AA[i]: i for i in range(len(AA))}
    encodings = []
    for i in fastas:
        sequence = re.sub('-', '', i[1])
        tmpCode = [0] * 64
        for j in range(len(sequence) - 2):
            index = AADict[sequence[j]] * 16 + AADict[sequence[j+1]] * 4 + AADict[sequence[j+2]]
            tmpCode[index] += 1
        total = sum(tmpCode)
        if total != 0:
            tmpCode = [x / total for x in tmpCode]
        encodings.append(tmpCode)
    return np.array(encodings)

def PseEIIP(fastas):
    base = 'ACGT'
    EIIP_dict = {'A': 0.1260, 'C': 0.1340, 'G': 0.0806, 'T': 0.1335}
    trincleotides = [x+y+z for x in base for y in base for z in base]
    EIIPxyz = {tri: sum(EIIP_dict[b] for b in tri) for tri in trincleotides}
    encodings = []
    for i in fastas:
        seq = re.sub('-', '', i[1])
        freq = Counter(seq[j:j+3] for j in range(len(seq)-2))
        total = sum(freq.values())
        freq = {k: v/total for k, v in freq.items()}
        code = [EIIPxyz[tri]*freq.get(tri, 0) for tri in trincleotides]
        encodings.append(code)
    return np.array(encodings)

def ENAC(fastas, window=5):
    AA = 'ACGT'
    encodings = []
    for i in fastas:
        seq = i[1]
        code = []
        for j in range(len(seq) - window + 1):
            count = Counter(seq[j:j+window])
            for aa in AA:
                code.append(count.get(aa, 0) / window)
        encodings.append(code)
    return np.array(encodings)

# === Main Processing ===
data_path = '/home/dl-lab-pc-2/PycharmProjects/m5C-Seq/Training Data/train_danio.fasta'
fastas = read_nucleotide_sequences(data_path)

encodings = {
    'CKSNAP': CKSNAP(fastas, gap=5),
    'NCP': NCP(fastas),
    'OneHot': dataProcessing(data_path, "fasta"),
    'TNC': TNC(fastas),
    'PseEIIP': PseEIIP(fastas),
    'ENAC': ENAC(fastas, window=5)
}

models = {
    'CKSNAP': RandomForestClassifier(n_estimators=500, max_depth=20, random_state=42),
    'NCP': LogisticRegression(max_iter=1000),
    'OneHot': SVC(kernel='rbf', probability=True),
    'TNC': XGBClassifier(n_estimators=300, max_depth=5, use_label_encoder=False, eval_metric='logloss', random_state=42),
    'PseEIIP': CatBoostClassifier(iterations=200, learning_rate=0.05, depth=6, verbose=0, random_seed=42),
    'ENAC': RandomForestClassifier(n_estimators=500, max_depth=25, random_state=42)
}

results = {}

def evaluate_encoding(X, y, model, encoding_name):
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    accs, mccs, sens, specs, f1s, precs, recs, pr_aucs = ([] for _ in range(8))
    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        accs.append(accuracy_score(y_test, y_pred))
        mccs.append(matthews_corrcoef(y_test, y_pred))
        sens.append(recall_score(y_test, y_pred))
        specs.append(confusion_matrix(y_test, y_pred)[0, 0] / sum(confusion_matrix(y_test, y_pred)[0]))
        f1s.append(f1_score(y_test, y_pred))
        precs.append(precision_score(y_test, y_pred))
        recs.append(recall_score(y_test, y_pred))

        precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred)
        pr_aucs.append(auc(recall_vals, precision_vals))

    results[encoding_name] = {
        'MCC': np.mean(mccs),
        'Accuracy': np.mean(accs),
        'Sensitivity': np.mean(sens),
        'Specificity': np.mean(specs),
        'F1': np.mean(f1s),
        'Precision': np.mean(precs),
        'Recall': np.mean(recs),
        'PR_AUC': np.mean(pr_aucs)
    }

# Create labels
y = np.array([1] * (len(fastas) // 2) + [0] * (len(fastas) // 2))

# Evaluate each encoding independently
for name, X_enc in encodings.items():
    print(f"\nEvaluating encoding: {name} with model: {models[name]._class.name_}")
    evaluate_encoding(X_enc, y, models[name], name)

# Fusion model with stacking
print("\nEvaluating Fusion Model (Stacking)")
X_fusion = np.concatenate([encodings[name] for name in encodings], axis=1)
base_learners = [(name, models[name]) for name in models]
stacking_model = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression(), cv=3)
evaluate_encoding(X_fusion, y, stacking_model, "Fusion")

# Print results
print("\n===== Evaluation Summary =====")
for name, metrics in results.items():
    print(f"\n--- {name} ---")
    for metric_name, value in metrics.items():
        print(f"{metric_name}: {value:.4f}")
